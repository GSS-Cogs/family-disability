{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gssutils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Environment: ZMQInteractiveShell; setting boo_pythonNB_environment to: True\n"
     ]
    }
   ],
   "source": [
    "if get_ipython().__class__.__name__ == 'ZMQInteractiveShell':\n",
    "    boo_pythonNB_environment = True\n",
    "else:\n",
    "    boo_pythonNB_environment = False\n",
    "\n",
    "print('Execution Environment: ' + get_ipython().__class__.__name__ + '; setting boo_pythonNB_environment to: ' \\\n",
    "      + str(boo_pythonNB_environment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Health state life expectancy, all ages, UK\n",
       "\n",
       "Pivot tables for health state life expectancy by sex and area type, divided by three-year intervals starting from 2009 to 2011.\n",
       "\n",
       "### Description\n",
       "\n",
       "Pivot tables for health state life expectancy by sex and area type, divided by two-year intervals starting from 2009 to 2011.\n",
       "\n",
       "### Distributions\n",
       "\n",
       "1. Health state life expectancy, all ages, UK ([MS Excel Spreadsheet](https://www.ons.gov.uk/file?uri=/peoplepopulationandcommunity/healthandsocialcare/healthandlifeexpectancies/datasets/healthstatelifeexpectancyallagesuk/current/heestimates.xlsx)) - 2016-11-29\n",
       "1. Health state life expectancy, all ages, UK ([application/zip](https://www.ons.gov.uk/file?uri=/peoplepopulationandcommunity/healthandsocialcare/healthandlifeexpectancies/datasets/healthstatelifeexpectancyallagesuk/current/previous/v1/healthexpectanciespivottables.zip)) - 2016-11-29\n",
       "1. Health state life expectancy, all ages, UK ([application/zip](https://www.ons.gov.uk/file?uri=/peoplepopulationandcommunity/healthandsocialcare/healthandlifeexpectancies/datasets/healthstatelifeexpectancyallagesuk/current/previous/v2/healthexpectanciespivottablesversion2.zip)) - 2016-11-29\n",
       "1. Health state life expectancy, all ages, UK ([MS Excel Spreadsheet](https://www.ons.gov.uk/file?uri=/peoplepopulationandcommunity/healthandsocialcare/healthandlifeexpectancies/datasets/healthstatelifeexpectancyallagesuk/current/previous/v3/refpivottablesfinal.xlsx)) - 2016-11-29\n",
       "1. Health state life expectancy, all ages, UK ([MS Excel Spreadsheet](https://www.ons.gov.uk/file?uri=/peoplepopulationandcommunity/healthandsocialcare/healthandlifeexpectancies/datasets/healthstatelifeexpectancyallagesuk/current/previous/v4/hslepivotab1.xlsx)) - 2016-11-29\n"
      ],
      "text/plain": [
       "<gssutils.scrape.Scraper at 0x1227cf7d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gssutils import *\n",
    "\n",
    "#if boo_pythonNB_environment == False:\n",
    "scraper = Scraper('https://www.ons.gov.uk/peoplepopulationandcommunity/healthandsocialcare/' \\\n",
    "                  'healthandlifeexpectancies/datasets/healthstatelifeexpectancyallagesuk')\n",
    "scraper\n",
    "\n",
    "#else:\n",
    "#    tabs = loadxlstabs('/Users/martyn/Downloads/hslepivotab1.xlsx') # Not significantly quicker with local read.\n",
    "# Download not the bottle-neck of the 50Mb file - read to memory is what is taking the time.    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Distribution</h3>\n",
       "<dl><dt>dct:title</dt><dd>&quot;Health state life expectancy, all ages, UK&quot;@en</dd>\n",
       "<dt>dct:description</dt><dd>&quot;Pivot tables for health state life expectancy by sex and area type, divided by two-year intervals starting from 2009 to 2011.&quot;@en</dd>\n",
       "<dt>dct:issued</dt><dd>&quot;2016-11-29&quot;^^&lt;http://www.w3.org/2001/XMLSchema#date&gt;</dd>\n",
       "<dt>dcat:downloadURL</dt><dd><a href=https://www.ons.gov.uk/file?uri=/peoplepopulationandcommunity/healthandsocialcare/healthandlifeexpectancies/datasets/healthstatelifeexpectancyallagesuk/current/heestimates.xlsx>&lt;https://www.ons.gov.uk/file?uri=/peoplepopulationandcommunity/healthandsocialcare/healthandlifeexpectancies/datasets/healthstatelifeexpectancyallagesuk/current/heestimates.xlsx&gt;</a></dd>\n",
       "<dt>dcat:mediaType</dt><dd>&quot;application/vnd.ms-excel&quot;</dd>\n",
       "</dl>"
      ],
      "text/plain": [
       "<gssutils.metadata.Distribution at 0x1227fed50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tabs = scraper.distributions[0].as_databaker()\n",
    "distribution = scraper.distributions[0]\n",
    "display(distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spreadsheet is 50Mb - note to developers - should we cut down the spreadsheet by deleting hidden columns etc. before processing? Each TAB is also calculated from pivot(s); the RAW data being hidden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H\n"
     ]
    }
   ],
   "source": [
    "str_tabsheetsinfocus = 'H'\n",
    "if boo_pythonNB_environment == True:\n",
    "    print(str_tabsheetsinfocus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More condensed code version of above... only one needed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Scanning: HE - Country level estimates\n",
      "Processed: HE - Country level estimates\n",
      " Scanning: HE - Region level estimates\n",
      "Processed: HE - Region level estimates\n",
      " Scanning: HE - MC,CA,WHB estimates\n",
      "Processed: HE - MC,CA,WHB estimates\n",
      " Scanning: HE - Local area estimates\n",
      "Processed: HE - Local area estimates\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "pd_df_name = []\n",
    "pd_df_cleaned = []\n",
    "import numpy as np\n",
    "for tab in tabs:\n",
    "    if tabs[i].name.startswith(str_tabsheetsinfocus):\n",
    "        \n",
    "        print(' Scanning: ' + tabs[i].name)\n",
    "\n",
    "        try:\n",
    "                pd_df_name.append(tabs[i].name)\n",
    "                pd_tab = distribution.as_pandas(sheet_name = tabs[i].name) #, skiprows=1, header=None)\n",
    "                \n",
    "                if tabs[i].name == 'HE - Country level estimates':\n",
    "                    pd_df_dimensions = pd_tab.iloc[:, :7]\n",
    "                    pd_df_observations = pd_tab.iloc[:, 7:14]\n",
    "                    pd_df_original = pd.concat([pd_df_dimensions, pd_df_observations], axis=1, sort=False)\n",
    "                    \n",
    "                if tabs[i].name == 'HE - Region level estimates':\n",
    "                    pd_df_dimensions = pd_tab.iloc[:, :8]\n",
    "                    pd_df_observations = pd_tab.iloc[:, 8:14]\n",
    "                    pd_df_original = pd.concat([pd_df_dimensions, pd_df_observations], axis=1, sort=False)\n",
    "                    pd_df_original.columns = pd_df_original.iloc[0]\n",
    "                    pd_df_original = pd_df_original[1:]\n",
    "                    \n",
    "                if tabs[i].name == 'HE - MC,CA,WHB estimates':\n",
    "                    pd_df_dimensions = pd_tab.iloc[:, :7]\n",
    "                    pd_df_observations = pd_tab.iloc[:, 7:14]\n",
    "                    pd_df_original = pd.concat([pd_df_dimensions, pd_df_observations], axis=1, sort=False)\n",
    "                    pd_df_original.columns = pd_df_original.iloc[0]\n",
    "                    pd_df_original = pd_df_original[1:]\n",
    "                \n",
    "                if tabs[i].name == 'HE - Local area estimates':\n",
    "                    pd_df_dimensions = pd_tab.iloc[:, :8]\n",
    "                    pd_df_observations = pd_tab.iloc[:, 8:15]\n",
    "                    pd_df_original = pd.concat([pd_df_dimensions, pd_df_observations], axis=1, sort=False)\n",
    "                    pd_df_original.columns = pd_df_original.iloc[0]\n",
    "                    pd_df_original = pd_df_original[1:]\n",
    "                \n",
    "                pd_df_original['Sex'] = np.where(pd_df_original['Sex'] == 'Males', 'M', pd_df_original['Sex'])\n",
    "                pd_df_original['Sex'] = np.where(pd_df_original['Sex'] == 'Females', 'F', pd_df_original['Sex'])\n",
    "                pd_df_original['Period'] = pd_df_original['Period'].map(lambda x: f'gregorian-interval/{str(x)[:4]}-03-31T00:00:00/P2Y')\n",
    "                #t[prd] = t[prd].map(lambda x: 'government-year/' + left(x,4) +'-20' + right(x,2))\n",
    "                pd_df_cleaned.append(pd_df_original.dropna(how='all'))    \n",
    "                print('Processed: ' + tabs[i].name)\n",
    "                \n",
    "        except ERR_HECountryLevelEstimates:\n",
    "                print('Error within ' + str(pd_df_name.append(tabs[i].name)) + ' process to extract to Pandas DF.')\n",
    "\n",
    "        \n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pd_df_dimensions, pd_df_observations, pd_df_original, pd_df_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is for testing purposes - not for final.\n",
    "#if boo_pythonNB_environment == True:\n",
    "    #for i in range(len(pd_df_name)):\n",
    "        #print('-------------------------------------------------------------------')\n",
    "        #print(pd_df_name[i])\n",
    "        #print('-------------------------------------------------------------------')\n",
    "        #display(pd_df_cleaned[i].head(3))\n",
    "        #print('Record Count: ' + str(pd_df_cleaned[i].shape[0]))\n",
    "        #print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd_df_cleaned[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Drop some column headings:\n",
    "try:\n",
    "    pd_df_cleaned[0] = pd_df_cleaned[0].drop(columns=['Country', 'sex1', 'ageband'])\n",
    "except Exception as e:\n",
    "    print(\"1. \" + str(e))\n",
    "try:\n",
    "    pd_df_cleaned[1] = pd_df_cleaned[1].drop(columns=['Area_name', 'sex1', 'ageband'])\n",
    "except Exception as e:\n",
    "    print(\"2. \" + str(e))\n",
    "try:\n",
    "    pd_df_cleaned[2] = pd_df_cleaned[2].drop(columns=['Area', 'sex1', 'ageband'])\n",
    "except Exception as e:\n",
    "    print(\"3. \" + str(e))\n",
    "try:\n",
    "    pd_df_cleaned[3] = pd_df_cleaned[3].drop(columns=['Country', 'Area_name', 'sex1', 'ageband'])\n",
    "except Exception as e:\n",
    "    print(\"4. \" + str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leigh - nothing below is ready - just random code snippets that can be deleted...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Rename some of the columns removing some characters (,),_,%,\"\n",
    "i = 0\n",
    "for t in pd_df_cleaned:\n",
    "    cols = pd.DataFrame(list(t))\n",
    "    cols.columns = ['ColumnNames']\n",
    "    cols = pd.DataFrame(cols['ColumnNames']\n",
    "                    .str.replace('(','')\n",
    "                    .str.replace(')','')\n",
    "                    .str.replace('_','')\n",
    "                    .str.replace('%','')\n",
    "                    .str.replace('''\"''','')\n",
    "                    .str.strip()\n",
    "                    )\n",
    "    #### Rename all the columns\n",
    "    t.columns = [cols.iloc[:, 0].tolist()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leigh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/leigh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/leigh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/leigh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/leigh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#### Rename some columns and change some values to match standard formats\n",
    "#### Then split each dataset into 3, rename so they all match and then concatenate\n",
    "import numpy as np\n",
    "genHead = \"Gender\"\n",
    "prd = \"Period\"\n",
    "ageRng = 'ONS Age Range'\n",
    "newColNme = \"Life Expectancy Estimate Type\"\n",
    "lciColNme = 'Lower CI'\n",
    "uciColNme = 'Upper CI'\n",
    "onsGeog = 'ONS Geography'\n",
    "i = 0\n",
    "for t in pd_df_cleaned:\n",
    "    try:\n",
    "        t = t.rename(columns={'Sex':genHead,'Code':onsGeog,'age group':ageRng,'Age group':ageRng})\n",
    "    except Exception as e:\n",
    "        print(f\"Renames: {i}. \" + str(e))\n",
    "        \n",
    "    try:\n",
    "        #### Split the table into 3, reconfigure some column nsmes and then concatenate\n",
    "        tbl1 = t[[prd,onsGeog,genHead,ageRng,'Life Expectancy LE','LE Lower CI','LE Upper CI']]\n",
    "        tbl2 = t[[prd,onsGeog,genHead,ageRng,'Healthy Life Expectancy HLE','HLE Lower CI','HLE Upper CI']]\n",
    "        tbl3 = t[[prd,onsGeog,genHead,ageRng,'Proportion of Life Spent in Good Health']]\n",
    "        #### Rename some columns so all 3 tables match ready for joining\n",
    "        tbl1[newColNme] = 'LE'\n",
    "        tbl1 = tbl1.rename(columns={'Life Expectancy LE':'Value','LE Lower CI':lciColNme,'LE Upper CI':uciColNme})\n",
    "        tbl2[newColNme] = 'HLE'\n",
    "        tbl2 = tbl2.rename(columns={'Healthy Life Expectancy HLE':'Value','HLE Lower CI':lciColNme,'HLE Upper CI':uciColNme})\n",
    "        tbl3[lciColNme] = ''\n",
    "        tbl3[uciColNme] = ''\n",
    "        tbl3[newColNme] = 'PLGH'\n",
    "        tbl3 = tbl3.rename(columns={'Proportion of Life Spent in Good Health':'Value'})\n",
    "\n",
    "        newTbl = pd.concat([tbl1,tbl2,tbl3])\n",
    "        pd_df_cleaned[i] = newTbl[[prd,onsGeog,genHead,ageRng,newColNme,lciColNme,uciColNme,'Value']]\n",
    "        #break\n",
    "    except Exception as e:\n",
    "        print(f\"Table Split: {i}. \" + str(e))\n",
    "    i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Set up the folder path for the output files\n",
    "from pathlib import Path\n",
    "\n",
    "out = Path('out')\n",
    "out.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "headSet = [\n",
    "    'HE Country level estimates',\n",
    "    'HE Region level estimates',\n",
    "    'HE MC CA WHB estimates',\n",
    "    'HE Local area estimates'\n",
    "]\n",
    "headMain = 'Pivot tables for health state life expectancy by sex and area type, - HE Country level estimates divided by two-year intervals starting from 2009 to 2011.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Gender\" not defined\n",
      "\"Age Group\" not defined\n",
      "\"Estimate Type\" not defined\n",
      "\"Lower CI\" not defined\n",
      "\"Upper CI\" not defined\n",
      "\"Gender\" not defined\n",
      "\"Age Group\" not defined\n",
      "\"Estimate Type\" not defined\n",
      "\"Lower CI\" not defined\n",
      "\"Upper CI\" not defined\n",
      "\"Gender\" not defined\n",
      "\"Age Group\" not defined\n",
      "\"Estimate Type\" not defined\n",
      "\"Lower CI\" not defined\n",
      "\"Upper CI\" not defined\n",
      "\"Gender\" not defined\n",
      "\"Age Group\" not defined\n",
      "\"Estimate Type\" not defined\n",
      "\"Lower CI\" not defined\n",
      "\"Upper CI\" not defined\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for t in pd_df_cleaned:\n",
    "    try:\n",
    "        fleNme =  headSet[i].replace(' ','-').lower() + '.csv'\n",
    "        hed =  headSet[i].replace(' ','-').lower()\n",
    "        t =  t.drop_duplicates()\n",
    "        t.to_csv(out / fleNme, index = False)\n",
    "    \n",
    "        scraper.set_dataset_id(f'gss_data/disability/ons-health-state-life-expectancy/{hed}/')\n",
    "    \n",
    "        scraper.dataset.family = 'disability'\n",
    "    \n",
    "        with open(out / ('pre' + fleNme + '-metadata.trig'), 'wb') as metadata:metadata.write(scraper.generate_trig())\n",
    "\n",
    "        csvw = CSVWMetadata('https://gss-cogs.github.io/family-disability/reference/')\n",
    "        csvw.create(out / fleNme, out / (fleNme + '-schema.json'))\n",
    "        i = i + 1\n",
    "        #break\n",
    "    except Exception as e:\n",
    "        print(f\"Table Split: {i}. \" + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### As each trig file is created multiple @prefix ns lines are added. This code gets rid of them\n",
    "\n",
    "import os\n",
    "i = 1 #### Main looping index\n",
    "k = 1 #### Secondary index to skip over lines with ns2\n",
    "lineWanted = False\n",
    "#### Loop around each element in the main heading list\n",
    "for t in headSet:\n",
    "    hed = t.replace(' ','-').lower()\n",
    "    newDat = ''\n",
    "    curNme = f'out/pre{hed}.csv-metadata.trig'    #### Current file name\n",
    "    newNme = f'out/{hed}.csv-metadata.trig'       #### New file name\n",
    "    #### Open the file and loop around each line adding or deleting as you go\n",
    "    with open(curNme, \"r\") as input:\n",
    "        #### Also open the new file to add to as you go\n",
    "        with open(newNme, \"w\") as output: \n",
    "            #### Loop around the input file\n",
    "            for line in input:\n",
    "                #### Change the lines to the value in the variabl headMain\n",
    "                if headMain in line.strip(\"\\n\"):\n",
    "                    newLine = line\n",
    "                    newLine = line.replace(headMain, headMain + ' - ' + t)\n",
    "                    output.write(newLine)\n",
    "                else: \n",
    "                    lineWanted = True\n",
    "                    #### Ignore lines with ns2 but loop for other ns# lines, deleteing any extra ones that do not match the value of k\n",
    "                    if '@prefix ns2:' not in line.strip(\"\\n\"):\n",
    "                        if '@prefix ns' in line.strip(\"\\n\"):\n",
    "                            if f'@prefix ns{k}:' not in line.strip(\"\\n\"):\n",
    "                                #### You do not want this line so ignore\n",
    "                                lineWanted = False\n",
    "                    #### If the line is needed check if it is a line that needs changing then write to new file \n",
    "                    if lineWanted: \n",
    "                        if 'a pmd:Dataset' in line.strip(\"\\n\"):\n",
    "                            line = line.replace(f'{hed}/', f'{hed}')\n",
    "                    \n",
    "                        if 'pmd:graph' in line.strip(\"\\n\"):\n",
    "                            line = line.replace(f'{hed}/', f'{hed}')\n",
    "                        #### Output the line to the new file                    \n",
    "                        output.write(line)\n",
    "                        \n",
    "    #### Close both files\n",
    "    input.close\n",
    "    output.close\n",
    "    #### Old trig file no longer needed so remove/delete\n",
    "    os.remove(curNme)\n",
    "\n",
    "    #### Increment i, ns2 is used for something else so you have got to jump k up by 1 at this point\n",
    "    i = i + 1\n",
    "    if i == 2:\n",
    "        k = k + 2\n",
    "    else:\n",
    "        k = k + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Notes - amendments link to cards? was 50mb now 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
